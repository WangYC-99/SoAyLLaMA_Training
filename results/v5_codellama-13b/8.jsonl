{"Query_en": "Research interests of Sergei Vassilvitskii at Google", "Answer": ["Online Advertising", "Information Retrieval", "Social Network", "Display Advertising", "K-means Method", "Computer Science", "K Means", "Indexation", "Inverted Index", "Mapreduce Framework"], "route": "searchPerson", "code": "info = {'name': 'Sergei Vassilvitskii', 'organization': 'Google'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ninterests = target_person_info['interests']\nfinal_result = interests\n", "result": ["Online Advertising", "Information Retrieval", "Social Network", "Display Advertising", "K-means Method", "Computer Science", "K Means", "Indexation", "Inverted Index", "Mapreduce Framework"], "exe_time": 2.102677822113037}
{"Query_en": "Citation count of Kai Shu at Department of Computer Science, College of Computing, Illinois Institute of Technology", "Answer": 8739, "route": "searchPerson", "code": "info = {'name': 'Kai Shu', 'organization': 'Department of Computer Science, College of Computing, Illinois Institute of Technology'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\nnum_citation = target_person_info['num_citation']\nfinal_result = num_citation\n", "result": 8739, "exe_time": 2.4250218868255615}
{"Query_en": "Number of published papers by Shoude Lin at Department of Computer Science and Information Engineering, National Taiwan University", "Answer": 194, "route": "searchPerson", "code": "info = {'name': 'Shoude Lin', 'organization': 'Department of Computer Science and Information Engineering, National Taiwan University'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\nnum_pubs = target_person_info['num_pubs']\nfinal_result = num_pubs\n", "result": 194, "exe_time": 2.3721964359283447}
{"Query_en": "Which institution does Yixin Su who researches in Yixin Su field belong to?", "Answer": "School of Computing and Information Systems, University of Melbourne", "route": "searchPerson", "code": "info = {'name': 'Yixin Su', 'interest': 'Yixin Su'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\norganization = target_person_info['organization']\nfinal_result = organization\n", "result": "School of Computing and Information Systems, University of Melbourne", "exe_time": 2.0435237884521484}
{"Query_en": "Citation count of Lingjiao Chen who researches in Public Key Encryption Scheme field", "Answer": 31, "route": "searchPerson", "code": "info = {'name': 'Lingjiao Chen', 'interest': 'Public Key Encryption Scheme'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\nnum_citation = target_person_info['num_citation']\nfinal_result = num_citation\n", "result": 31, "exe_time": 2.246586799621582}
{"Query_en": "Number of papers published by Cynthia B Phillips who researches in Anomaly Detection field", "Answer": 37, "route": "searchPerson", "code": "info = {'name': 'Cynthia B Phillips', 'interest': 'Anomaly Detection'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\nnum_pubs = target_person_info['num_pubs']\nfinal_result = num_pubs\n", "result": 37, "exe_time": 2.2840664386749268}
{"Query_en": "Who are the researchers at Department of Artificial Intelligence, School of Informatics, Department of Artificial Intelligence, School of Informatics, Xiamen Universityiamen University?", "Answer": ["Rongrong Ji"], "route": "searchPerson", "code": "info = {'organization': 'Department of Artificial Intelligence, School of Informatics, Xiamen University'}\norganization = info['organization']\n\nperson_list = searchPerson(organization = organization)\nname_list = [person_list[i]['name'] for i in range(len(person_list))]\nfinal_result = name_list\n", "result": ["Rongrong Ji"], "exe_time": 2.008071184158325}
{"Query_en": "Who are the researchers in Brain Imaging Genetics field?", "Answer": ["Kefei Liu"], "route": "searchPerson", "code": "info = {'interest': 'Brain Imaging Genetics'}\ninterest = info['interest']\n\nperson_list = searchPerson(interest = interest)\nname_list = [person_list[i]['name'] for i in range(len(person_list))]\nfinal_result = name_list\n", "result": ["Kefei Liu"], "exe_time": 1.7279648780822754}
{"Query_en": "Who are the collaborators of Zhixin Zhou at Department of Management Sciences, College of Business, City University of Hong Kong?", "Answer": ["Zhaozhuo Xu (Otto)", "Shulong Tan", "Arash Ali Amini", "Weijie Zhao", "Ping Li", "Shaogang Ren"], "route": "searchPerson -> getCoauthors", "code": "info = {'name': 'Zhixin Zhou', 'organization': 'Department of Management Sciences, College of Business, City University of Hong Kong'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ncoauthors_list = getCoauthors(person_id = target_person_id)\ncoauthors_name_list = [coauthor['name'] for coauthor in coauthors_list]\nfinal_result = coauthors_name_list\n", "result": ["Zhaozhuo Xu (Otto)", "Shulong Tan", "Arash Ali Amini", "Weijie Zhao", "Ping Li", "Shaogang Ren"], "exe_time": 3.555211305618286}
{"Query_en": "Who are the collaborators of Vaggos Chatziafratis in Dynamical Systems field?", "Answer": ["Moses Charikar", "Mohammad Mahdian", "Sara Ahmadian", "Grigory Yaroslavtsev", "Pranjal Awasthi", "Sepehr Assadi", "Alessandro Epasto", "Yossi Azar", "Avrim Blum", "Albert Gu", "Vahab S. Mirrokni"], "route": "searchPerson -> getCoauthors", "code": "info = {'name': 'Vaggos Chatziafratis', 'interest': 'Dynamical Systems'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ncoauthors_list = getCoauthors(person_id = target_person_id)\ncoauthors_name_list = [coauthor['name'] for coauthor in coauthors_list]\nfinal_result = coauthors_name_list\n", "result": ["Moses Charikar", "Mohammad Mahdian", "Sara Ahmadian", "Grigory Yaroslavtsev", "Pranjal Awasthi", "Sepehr Assadi", "Alessandro Epasto", "Yossi Azar", "Avrim Blum", "Albert Gu", "Vahab S. Mirrokni"], "exe_time": 3.355325222015381}
{"Query_en": "Who at Department of Computer Science and Engineering, The Chinese University of Hong Kong has a collaboration with Menglin Yang?", "Answer": ["Yankai Chen"], "route": "searchPerson -> getCoauthors", "code": "info = {'name': 'Menglin Yang', 'organization': 'Department of Computer Science and Engineering, The Chinese University of Hong Kong'}\norganization = info['organization']\nname = info['name']\n\norganization_person_list = searchPerson(organization = organization)\norganization_person_id_list = [person['person_id'] for person in organization_person_list]\ntarget_list = []\nfor interest_person_id in organization_person_id_list:\n    coauthors = getCoauthors(person_id = interest_person_id)\n    coauthor_name_list = [coauthor['name'] for coauthor in coauthors]\n    if name in coauthor_name_list:\n        target_list.append(getPersonBasicInfo(person_id=interest_person_id)['name'])\nfinal_result = target_list\n", "result": ["Yankai Chen"], "exe_time": 4.48190712928772}
{"Query_en": "Who in Online Influence Maximization field has a collaboration with Zhige Li?", "Answer": ["Qingyun Wu", "Huazheng Wang"], "route": "searchPerson -> getCoauthors", "code": "info = {'name': 'Zhige Li', 'interest': 'Online Influence Maximization'}\ninterest = info['interest']\nname = info['name']\n\ninterest_person_list = searchPerson(interest = interest)\ninterest_person_id_list = [person['person_id'] for person in interest_person_list]\ntarget_list = []\nfor interest_person_id in interest_person_id_list:\n    coauthors = getCoauthors(person_id = interest_person_id)\n    coauthor_name_list = [coauthor['name'] for coauthor in coauthors]\n    if name in coauthor_name_list:\n        target_list.append(getPersonBasicInfo(person_id=interest_person_id)['name'])\nfinal_result = target_list\n", "result": ["Qingyun Wu", "Huazheng Wang"], "exe_time": 4.334338426589966}
{"Query_en": "What are the papers published by Johann Hibschman at Google?", "Answer": ["Constructing High Precision Knowledge Bases with Subjective and Factual Attributes."], "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Johann Hibschman', 'organization': 'Google'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\npublications_list = getPersonPubs(person_id = target_person_id)\npublications_title_list = [publication['title'] for publication in publications_list]\nfinal_result = publications_title_list\n", "result": ["Constructing High Precision Knowledge Bases with Subjective and Factual Attributes."], "exe_time": 3.1494016647338867}
{"Query_en": "What is the citation count of the representative work of Pablo Estevez at Booking.com?", "Answer": 104, "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Pablo Estevez', 'organization': 'Booking.com'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\npublications_list = getPersonPubs(person_id = target_person_id)\n# Assuming the representative work is the one with the most citations\n# The list was sorted by citation\nmax_citation = publications_list[0]\nfinal_result = max_citation['num_citation']\n", "result": 104, "exe_time": 3.5251176357269287}
{"Query_en": "In which year was the representative work of Muhammad Bilal Zafar at Amazon Web Services published?", "Answer": 2017, "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Muhammad Bilal Zafar', 'organization': 'Amazon Web Services'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\npublications_list = getPersonPubs(person_id = target_person_id)\n# Assuming the representative work is the one with the most citations\n# The list was sorted by citation\nmax_citation = publications_list[0]\nfinal_result = max_citation['num_citation']\n", "result": 1135, "exe_time": 3.6321802139282227}
{"Query_en": "Who are the authors of the representative work of Paulo Orenstein at Department of Statistics, Stanford University?", "Answer": ["Jessica Hwang", "Paulo Orenstein", "Karl Pfeiffer", "Judah Cohen", "Lester Mackey"], "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Paulo Orenstein', 'organization': 'Department of Statistics, Stanford University'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\npublications_list = getPersonPubs(person_id = target_person_id)\n# The list was sorted by citation\nmax_citation = publications_list[0]\nfinal_result = max_citation['year']\n", "result": 2019, "exe_time": 3.301542043685913}
{"Query_en": "What are the papers published by Bailin Wang in State-of-the-art Performance field?", "Answer": ["RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL  Parsers", "Neural Segmental Hypergraphs for Overlapping Mention Recognition.", "A Neural Transition-based Model for Nested Mention Recognition.", "Learning Latent Opinions for Aspect-level Sentiment Classification.", "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models", "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing", "Meta-Learning for Domain Generalization in Semantic Parsing", "Meta-Learning to Compositionally Generalize.", "Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs", "Learning to Synthesize Data for Semantic Parsing"], "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Bailin Wang', 'interest': 'State-of-the-art Performance'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name=name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\npublications_list = getPersonPubs(person_id = target_person_id)\npublications_title_list = [publication['title'] for publication in publications_list]\nfinal_result = publications_title_list\n", "result": ["RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL  Parsers", "Neural Segmental Hypergraphs for Overlapping Mention Recognition.", "A Neural Transition-based Model for Nested Mention Recognition.", "Learning Latent Opinions for Aspect-level Sentiment Classification.", "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models", "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing", "Meta-Learning for Domain Generalization in Semantic Parsing", "Meta-Learning to Compositionally Generalize.", "Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs", "Learning to Synthesize Data for Semantic Parsing"], "exe_time": 3.219933032989502}
{"Query_en": "What is the citation count of the representative work of Ruili Feng in Image And Video Synthesis And Generation field?", "Answer": 49, "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Ruili Feng', 'interest': 'Image And Video Synthesis And Generation'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\n# The list was sorted by citation\ntarget_publication_dict = target_person_pubs[0]\ntarget_num_citation = target_publication_dict['num_citation']\nfinal_result = target_num_citation\n", "result": 49, "exe_time": 3.7664711475372314}
{"Query_en": "In which year was the representative work of Alina Ene in Approximation Algorithms field published?", "Answer": 2011, "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Alina Ene', 'interest': 'Approximation Algorithms'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\n# The list was sorted by citation\ntarget_publication_dict = target_person_pubs[0]\ntarget_num_citation = target_publication_dict['num_citation']\nfinal_result = target_num_citation\n", "result": 280, "exe_time": 3.733236074447632}
{"Query_en": "Who are the authors of the representative work of Alexander Marx in Causal Inference field?", "Answer": ["Alexander Marx", "Christina Backes", "Eckart Meese", "Hans-Peter Lenhof", "Andreas Keller"], "route": "searchPerson -> getPersonPubs", "code": "info = {'name': 'Alexander Marx', 'interest': 'Causal Inference'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\n# The list was sorted by citation\ntarget_publication_dict = target_person_pubs[0]\nauthor_name_list = target_publication_dict['authors_name_list']\nfinal_result = author_name_list\n", "result": ["Alexander Marx", "Christina Backes", "Eckart Meese", "Hans-Peter Lenhof", "Andreas Keller"], "exe_time": 3.696894407272339}
{"Query_en": "Is Matti Karppa at Basic Algorithms Research Copenhagen, IT University of Copenhagen male or female?", "Answer": "male", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Matti Karppa', 'organization': 'Basic Algorithms Research Copenhagen, IT University of Copenhagen'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_gender = target_person_basic_info['gender']\nfinal_result = target_person_gender\n", "result": "male", "exe_time": 3.3156917095184326}
{"Query_en": "What is the title of Jane Jing at Facebook?", "Answer": "Engineer", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Jane Jing', 'organization': 'Facebook'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_position = target_person_basic_info['position']\nfinal_result = target_person_position\n", "result": "Engineer", "exe_time": 3.0801193714141846}
{"Query_en": "What is the introduction of Zhaonan Sun at IBM?", "Answer": "Professional Experience<br>Aug 2015 to present, Research Staff Member, IBM T.J. Watson Research Center<br>Aug 2014 to July 2015, Postdoctoral Researcher, IBM T.J. Watson Research Center", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Zhaonan Sun', 'organization': 'IBM'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_bio = target_person_basic_info['bio']\nfinal_result = target_person_bio\n", "result": "Professional Experience<br>Aug 2015 to present, Research Staff Member, IBM T.J. Watson Research Center<br>Aug 2014 to July 2015, Postdoctoral Researcher, IBM T.J. Watson Research Center", "exe_time": 3.0931873321533203}
{"Query_en": "What is the educational background of Julien Audibert at Orange?", "Answer": "", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Julien Audibert', 'organization': 'Orange'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_education_experience = target_person_basic_info['education_experience']\nfinal_result = target_person_education_experience\n", "result": "", "exe_time": 3.452788829803467}
{"Query_en": "What is the email of Simon S. Woo at Department of Applied Data Science, Sungkyunkwan University?", "Answer": "swoo@g.skku.edu", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Simon S. Woo', 'organization': 'Department of Applied Data Science, Sungkyunkwan University'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_email = target_person_basic_info['email']\nfinal_result = target_person_email\n", "result": "swoo@g.skku.edu", "exe_time": 3.3770594596862793}
{"Query_en": "Is Ge Chen in Frequency Capping field male or female?", "Answer": "unknown", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Ge Chen', 'interest': 'Frequency Capping'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_gender = target_person_basic_info['gender']\nfinal_result = target_person_gender\n", "result": "unknown", "exe_time": 3.076221466064453}
{"Query_en": "What is the title of Yining Chen in Planning field?", "Answer": "Ph.D", "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Yining Chen', 'interest': 'Planning'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_abstract = target_publication_info['abstract']\nfinal_result = target_abstract\n", "result": "  Self-training algorithms, which train a model to fit pseudolabels predicted by another previously-learned model, have been very successful for learning with unlabeled data using neural networks. However, the current theoretical understanding of self-training only applies to linear models. This work provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. At the core of our analysis is a simple but realistic \"expansion\" assumption, which states that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. We also assume that neighborhoods of examples in different classes have minimal overlap. We prove that under these assumptions, the minimizers of population objectives based on self-training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. By using off-the-shelf generalization bounds, we immediately convert this result to sample complexity guarantees for neural nets that are polynomial in the margin and Lipschitzness. Our results help explain the empirical successes of recently proposed self-training algorithms which use input consistency regularization. ", "exe_time": 4.195162534713745}
{"Query_en": "What is the introduction of Fengyi Tang in Electronic Health Records field?", "Answer": "His project involves data mining Electronic Health Records (EHR) and building prognostic tools for determining probability of readmission for congestive heart failure patients within a 180-day prediction window. He is investigating the outcomes of two aims in medical informatics research: 1) formulating medical prognostics into machine learning problems and 2) identifying new ways to phenotype patients to corresponding disease patterns among populations. He is a PhD student in the Department of Computer Science and Engineering.", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Fengyi Tang', 'interest': 'Electronic Health Records'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_bio = target_person_basic_info['bio']\nfinal_result = target_person_bio\n", "result": "His project involves data mining Electronic Health Records (EHR) and building prognostic tools for determining probability of readmission for congestive heart failure patients within a 180-day prediction window. He is investigating the outcomes of two aims in medical informatics research: 1) formulating medical prognostics into machine learning problems and 2) identifying new ways to phenotype patients to corresponding disease patterns among populations. He is a PhD student in the Department of Computer Science and Engineering.", "exe_time": 3.1778526306152344}
{"Query_en": "What is the educational background of Junyi Li in Frontal Cortex field?", "Answer": "", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Junyi Li', 'interest': 'Frontal Cortex'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_education_experience = target_person_basic_info['education_experience']\nfinal_result = target_person_education_experience\n", "result": "", "exe_time": 3.4722304344177246}
{"Query_en": "What is the email of Ronaldo Cristiano Prati in Machine Learning field?", "Answer": "ronaldo.prati@ufabc.edu.br", "route": "searchPerson -> getPersonBasicInfo", "code": "info = {'name': 'Ronaldo Cristiano Prati', 'interest': 'Machine Learning'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_basic_info = getPersonBasicInfo(person_id = target_person_id)\ntarget_person_email = target_person_basic_info['email']\nfinal_result = target_person_email\n", "result": "ronaldo.prati@ufabc.edu.br", "exe_time": 3.1393017768859863}
{"Query_en": "Who among the collaborators of Chandan K. Reddy at Department of Computer Science, Virginia Tech are researching in Machine Learning field?", "Answer": ["Yan Li", "Naren Ramakrishnan"], "route": "searchPerson -> getCoauthors -> searchPerson", "code": "info = {'name': 'Chandan K. Reddy', 'organization': 'Department of Computer Science, Virginia Tech'}\nname = info['name']\norganization = info['organization']\ntarget_interest = info['interest']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ncoauthor_list = getCoauthors(person_id = target_person_id)\n\ntarget_coauthor_names = []\nfor coauthor in coauthor_list:\n    coauthor_id = coauthor['person_id']\n    coauthor_interests_list = getPersonInterest(person_id = coauthor_id)\n    if target_interest in coauthor_interests_list:\n        target_coauthor_names.append(coauthor['name'])\n\nfinal_result = target_coauthor_names\n", "result": "exe error", "exe_time": 5.003278493881226}
{"Query_en": "Who has the highest citation count among the collaborators of Avrilia Floratou at Microsoft?", "Answer": "Markus Weimer", "route": "searchPerson -> getCoauthors -> searchPerson", "code": "info = {'name': 'Avrilia Floratou', 'organization': 'Microsoft'}\nname = info['name']\norganization = info['organization']\n\n# get specific person's information\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\n\n# get coauthors of the specific person\ncoauthors_list = getCoauthors(person_id = target_person_id)\n\n# get information of coauthors and find the one with highest citation\nmax_citation = 0\nmax_citation_author_name = ''\n\nfor coauthor in coauthors_list:\n    coauthor_name = coauthor['name']\n    coauthor_info_list = searchPerson(name = coauthor_name)\n    coauthor_info = coauthor_info_list[0]\n    coauthor_citation = coauthor_info['num_citation']\n    if coauthor_citation > max_citation:\n        max_citation = coauthor_citation\n        max_citation_author_name = coauthor_info['name']\n\nfinal_result = max_citation_author_name\n", "result": "Markus Weimer", "exe_time": 6.340731143951416}
{"Query_en": "Who has the most published papers among the collaborators of Nicolas Perrin at Criteo?", "Answer": "Nicolas Grislain", "route": "searchPerson -> getCoauthors -> searchPerson", "code": "info = {'name': 'Nicolas Perrin', 'organization': 'Criteo'}\nname = info['name']\norganization = info['organization']\n\n# Search the person\nperson_list = searchPerson(name=name, organization=organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\n\n# Get the coauthors\ncoauthors_list = getCoauthors(person_id=target_person_id)\n\n# get information of coauthors and find the one with highest citation\nmax_pubs = 0\nmax_pubs_author_name = ''\n\n# Iterate each coauthor and calculate his/her publication number\nfor coauthor in coauthors_list:\n    coauthor_name = coauthor['name']\n    coauthor_info_list = searchPerson(name = coauthor_name)\n    coauthor_info = coauthor_info_list[0]\n    coauthor_pubs = coauthor_info['num_pubs']\n    if coauthor_pubs > max_pubs:\n        max_pubs = coauthor_pubs\n        max_pubs_author_name = coauthor_info['name']\n\nfinal_result = max_pubs_author_name\n", "result": "Nicolas Grislain", "exe_time": 6.5407257080078125}
{"Query_en": "Who among the collaborators of Ting Liu in Natural Language Processing field are at School of Computer Science and Technology, Harbin Institute of Technologyinstitution?", "Answer": ["Bing Qin"], "route": "searchPerson -> getCoauthors -> searchPerson", "code": "info = {'name': 'Ting Liu', 'interest': 'Natural Language Processing'}\nname = info['name']\ninterest = info['interest']\ntarget_organization = info['organization']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ncoauthor_list = getCoauthors(person_id = target_person_id)\n\ntarget_coauthor_names = []\nfor coauthor in coauthor_list:\n    coauthor_name = coauthor['name']\n    coauthor_list = searchPerson(name = coauthor_name)\n    coauthor_info = coauthor_list[0]\n    coauthor_organization = coauthor_info['organization']\n    if coauthor_organization == target_organization:\n        target_coauthor_names.append(coauthor['name'])\n\nfinal_result = target_coauthor_names\n", "result": "exe error", "exe_time": 5.2329018115997314}
{"Query_en": "Who has the highest citation count among the collaborators of Tsang Michael in Gesture Recognition field?", "Answer": "Yan Liu", "route": "searchPerson -> getCoauthors -> searchPerson", "code": "info = {'name': 'Tsang Michael', 'interest': 'Gesture Recognition'}\nname = info['name']\ninterest = info['interest']\n\n# get specific person's information\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\n\n# Get the coauthors\ncoauthors_list = getCoauthors(person_id=target_person_id)\n\n# get information of coauthors and find the one with highest citation\nmax_citation = 0\nmax_citation_author_name = ''\n\n# Iterate each coauthor and calculate his/her citation\nfor coauthor in coauthors_list:\n    coauthor_name = coauthor['name']\n    coauthor_info_list = searchPerson(name = coauthor_name)\n    coauthor_info = coauthor_info_list[0]\n    coauthor_citation = coauthor_info['num_citation']\n    if coauthor_citation > max_citation:\n        max_citation = coauthor_citation\n        max_citation_author_name = coauthor_info['name']\n\nfinal_result = max_citation_author_name\n", "result": "Yan Liu", "exe_time": 6.58138108253479}
{"Query_en": "Who has the most published papers among the collaborators of Yiwen Zhu in Machine Learning field?", "Answer": "Zeeshan Ahmed", "route": "searchPerson -> getCoauthors -> searchPerson", "code": "info = {'name': 'Yiwen Zhu', 'interest': 'Machine Learning'}\nname = info['name']\ninterest = info['interest']\n\n# get specific person's information\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\n\n# Get the coauthors\ncoauthors_list = getCoauthors(person_id=target_person_id)\n\n# get information of coauthors and find the one with highest citation\nmax_pubs = 0\nmax_pubs_author_name = ''\n\n# Iterate each coauthor and calculate his/her publication number\nfor coauthor in coauthors_list:\n    coauthor_name = coauthor['name']\n    coauthor_info_list = searchPerson(name = coauthor_name)\n    coauthor_info = coauthor_info_list[0]\n    coauthor_pubs = coauthor_info['num_pubs']\n    if coauthor_pubs > max_pubs:\n        max_pubs = coauthor_pubs\n        max_pubs_author_name = coauthor_info['name']\n\nfinal_result = max_pubs_author_name\n", "result": "Zeeshan Ahmed", "exe_time": 6.569897890090942}
{"Query_en": "Who are the collaborators of the collaborators of Tao Shen at University of Technology Sydney?", "Answer": ["Jing Jiang", "Chengqi Zhang", "Shirui Pan", "Tao Shen", "Lina Yao", "Xianzhi Wang", "Peng Zhang", "Xingquan Zhu", "Xiaojun Chang", "Guandong Xu", "Shuang Ao", "Yue Tan", "Guodong Long", "Chengqi Zhang", "Shirui Pan", "Tao Shen", "Jiang Bian", "Lina Yao", "Guangquan Zhang", "Jie Lu", "Xingquan Zhu", "Yue Tan", "Zhiyu Mou", "Shuang Ao", "Liming Zhu", "Longbing Cao", "Guodong Long", "Xingquan Zhu", "Shichao Zhang", "Ling Chen", "Jing Jiang", "Shirui Pan", "Xindong Wu", "Philip S. Yu", "Peng Zhang", "Bin Li", "Jie Yin", "Tao Shen", "Haishuai Wang", "Xu Yu", "Bing Liu", "Lei Chen", "Zhenxin Fu", "Weiguo Zheng", "Wei Wu", "Xu Yu", "Mingyue Shang", "Feng Ji", "Lina Yao", "Guandong Xu", "Lei Bai", "Manqing Dong", "Xiang Zhang", "Guodong Long", "Wenjie Zhang", "Zheng Yang", "Liming Zhu", "Xiaojun Chang", "Tie-Yan Liu", "Xu Tan", "Lijun Wu", "Li Zhao", "Hang Li", "Jinhua Zhu", "Jiang Bian", "Yi Ren", "Sheng Zhao", "Yichong Leng", "Kaitao Song", "Chang Liu", "Jianhuang Lai", "Enhong Chen", "Zhou Zhao", "Jin Xu", "Jian Li", "Jie Lu", "Zheng Yan", "Zhen Fang", "Tianrui Li", "Mahardhika Pratama", "Qi Tian", "Dacheng Tao", "Furu Wei", "Yang Yang", "Xi Chen (Stephen)", "Kuang-Huei Lee", "Kuansan Wang", "Guangquan Zhang", "Zheng Yan", "Zhen Fang", "Mahardhika Pratama", "Tianrui Li", "Jiawei Han", "Ke Wang", "Xuemin Lin", "Philip S. Yu", "Lingyang Chu", "Linjun Shou", "Peng Cui", "Yufei Tao", "Yu Yang", "Jianyong Wang", "Enhong Chen", "Heng Huang", "Aidong Zhang", "James Bailey", "Raymond Chi-Wing Wong", "Hang Li", "Wenwu Zhu", "Wenjie Zhang", "Xindong Wu", "Jiannan Wang", "Jun Luo", "Longbing Cao", "Yixin Chen", "Ziwei Zhang", "Lingfei Wu (Teddy)"], "route": "searchPerson -> getCoauthors -> getCoauthors", "code": "info = {'name': 'Tao Shen', 'organization': 'University of Technology Sydney'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ncoauthors1_list = getCoauthors(person_id = target_person_id)\n\ncoauthors2_list = []\nfor coauthor in coauthors1_list:\n    coauthors2_list.extend(getCoauthors(person_id = coauthor['person_id']))\n\ncoauthors2_names = [coauthor['name'] for coauthor in coauthors2_list]\n\nfinal_result = coauthors2_names\n", "result": ["Jing Jiang", "Chengqi Zhang", "Shirui Pan", "Tao Shen", "Lina Yao", "Xianzhi Wang", "Peng Zhang", "Xingquan Zhu", "Xiaojun Chang", "Guandong Xu", "Shuang Ao", "Yue Tan", "Guodong Long", "Chengqi Zhang", "Shirui Pan", "Tao Shen", "Jiang Bian", "Lina Yao", "Guangquan Zhang", "Jie Lu", "Xingquan Zhu", "Yue Tan", "Zhiyu Mou", "Shuang Ao", "Liming Zhu", "Longbing Cao", "Guodong Long", "Xingquan Zhu", "Shichao Zhang", "Ling Chen", "Jing Jiang", "Shirui Pan", "Xindong Wu", "Philip S. Yu", "Peng Zhang", "Bin Li", "Jie Yin", "Tao Shen", "Haishuai Wang", "Xu Yu", "Bing Liu", "Lei Chen", "Zhenxin Fu", "Weiguo Zheng", "Wei Wu", "Xu Yu", "Mingyue Shang", "Feng Ji", "Lina Yao", "Guandong Xu", "Lei Bai", "Manqing Dong", "Xiang Zhang", "Guodong Long", "Wenjie Zhang", "Zheng Yang", "Liming Zhu", "Xiaojun Chang", "Tie-Yan Liu", "Xu Tan", "Lijun Wu", "Li Zhao", "Hang Li", "Jinhua Zhu", "Jiang Bian", "Yi Ren", "Sheng Zhao", "Yichong Leng", "Kaitao Song", "Chang Liu", "Jianhuang Lai", "Enhong Chen", "Zhou Zhao", "Jin Xu", "Jian Li", "Jie Lu", "Zheng Yan", "Zhen Fang", "Tianrui Li", "Mahardhika Pratama", "Qi Tian", "Dacheng Tao", "Furu Wei", "Yang Yang", "Xi Chen (Stephen)", "Kuang-Huei Lee", "Kuansan Wang", "Guangquan Zhang", "Zheng Yan", "Zhen Fang", "Mahardhika Pratama", "Tianrui Li", "Jiawei Han", "Ke Wang", "Xuemin Lin", "Philip S. Yu", "Lingyang Chu", "Linjun Shou", "Peng Cui", "Yufei Tao", "Yu Yang", "Jianyong Wang", "Enhong Chen", "Heng Huang", "Aidong Zhang", "James Bailey", "Raymond Chi-Wing Wong", "Hang Li", "Wenwu Zhu", "Wenjie Zhang", "Xindong Wu", "Jiannan Wang", "Jun Luo", "Longbing Cao", "Yixin Chen", "Ziwei Zhang", "Lingfei Wu (Teddy)"], "exe_time": 4.42111349105835}
{"Query_en": "Who are the collaborators of the collaborators of Tim Brooks in Synthesize Motion Blur field?", "Answer": ["Zhihao Jia", "Michael I. Jordan", "Osbert Bastani", "Weili Nie", "Qinsheng Zhang", "Connor Z. Lin", "Jon Hasselgren", "Axel Levy", "Alexander W. Bergman", "Arun Mallya"], "route": "searchPerson -> getCoauthors -> getCoauthors", "code": "info = {'name': 'Tim Brooks', 'interest': 'Synthesize Motion Blur'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ncoauthors1_list = getCoauthors(person_id = target_person_id)\n\ncoauthors2_list = []\nfor coauthor in coauthors1_list:\n    coauthors2_list.extend(getCoauthors(person_id = coauthor['person_id']))\n\ncoauthors2_names = [coauthor['name'] for coauthor in coauthors2_list]\n\nfinal_result = coauthors2_names\n", "result": ["Zhihao Jia", "Michael I. Jordan", "Osbert Bastani", "Weili Nie", "Qinsheng Zhang", "Connor Z. Lin", "Jon Hasselgren", "Axel Levy", "Alexander W. Bergman", "Arun Mallya"], "exe_time": 4.420738697052002}
{"Query_en": "What is the abstract of the representative work of Bruno Veloso at LIAAD - INESC TEC?", "Answer": "The widespread usage of smart devices and sensors together with the ubiquity of the Internet access is behind the exponential growth of data streams. Nowadays, there are hundreds of machine learning algorithms able to process high-speed data streams. However, these algorithms rely on human expertise to perform complex processing tasks like hyper-parameter tuning. This paper addresses the problem of data variability modelling in data streams. Specifically, we propose and evaluate a new parameter tuning algorithm called Self Parameter Tuning (SPT). SPT consists of an online adaptation of the Nelder u0026 Mead optimisation algorithm for hyper-parameter tuning. The method explores a dynamic size sample method to evaluate the current solution, and uses the Nelder u0026 Mead operators to update the current set of parameters. The main contribution is the adaptation of the Nelder-Mead algorithm to automatically tune regression hyper-parameters for data streams. Additionally, whenever concept drifts occur in the data stream, it re-initiates the search for new hyper-parameters. The proposed method has been evaluated on regression scenario. Experiments with well known time-evolving data streams show that the proposed SPT hyper-parameter optimisation outperforms the results of previous expert hyper-parameter tuning efforts.", "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Bruno Veloso', 'organization': 'LIAAD - INESC TEC'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_abstract = target_publication_info['abstract']\nfinal_result = target_abstract\n", "result": "The widespread usage of smart devices and sensors together with the ubiquity of the Internet access is behind the exponential growth of data streams. Nowadays, there are hundreds of machine learning algorithms able to process high-speed data streams. However, these algorithms rely on human expertise to perform complex processing tasks like hyper-parameter tuning. This paper addresses the problem of data variability modelling in data streams. Specifically, we propose and evaluate a new parameter tuning algorithm called Self Parameter Tuning (SPT). SPT consists of an online adaptation of the Nelder u0026 Mead optimisation algorithm for hyper-parameter tuning. The method explores a dynamic size sample method to evaluate the current solution, and uses the Nelder u0026 Mead operators to update the current set of parameters. The main contribution is the adaptation of the Nelder-Mead algorithm to automatically tune regression hyper-parameters for data streams. Additionally, whenever concept drifts occur in the data stream, it re-initiates the search for new hyper-parameters. The proposed method has been evaluated on regression scenario. Experiments with well known time-evolving data streams show that the proposed SPT hyper-parameter optimisation outperforms the results of previous expert hyper-parameter tuning efforts.", "exe_time": 4.372052431106567}
{"Query_en": "What is the PDF link of the representative work of Sungchul Kim at Adobe Research?", "Answer": "https://static.aminer.cn/upload/pdf/program/5aed148b17c44a4438154eb3_0.pdf", "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Sungchul Kim', 'organization': 'Adobe Research'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_pdf = target_publication_info['pdf_link']\nfinal_result = target_pdf\n", "result": "https://static.aminer.cn/upload/pdf/program/5aed148b17c44a4438154eb3_0.pdf", "exe_time": 4.28337287902832}
{"Query_en": "Which journal or conference included the representative work of Lei Guo at School of Information Science and Engineering, Shandong Normal University?", "Answer": {"name": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining"}, "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Lei Guo', 'organization': 'School of Information Science and Engineering, Shandong Normal University'}\nname = info['name']\norganization = info['organization']\n\nperson_list = searchPerson(name = name, organization = organization)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_venue = target_publication_info['venue']\nfinal_result = target_venue\n", "result": {"name": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining"}, "exe_time": 4.422482490539551}
{"Query_en": "What is the abstract of the representative work of Ruixiang Tang in Chest Ct field?", "Answer": "With the widespread use of deep neural networks (DNNs) in high-stake applications, the security problem of the DNN models has received extensive attention. In this paper, we investigate a specific security problem called trojan attack, which aims to attack deployed DNN systems relying on the hidden trigger patterns inserted by malicious hackers. We propose a training-free attack approach which is different from previous work, in which trojaned behaviors are injected by retraining model on a poisoned dataset. Specifically, we do not change parameters in the original model but insert a tiny trojan module (TrojanNet) into the target model. The infected model with a malicious trojan can misclassify inputs into a target label when the inputs are stamped with the special trigger. The proposed TrojanNet has several nice properties including (1) it activates by tiny trigger patterns and keeps silent for other signals, (2) it is model-agnostic and could be injected into most DNNs, dramatically expanding its attack scenarios, and (3) the training-free mechanism saves massive training efforts comparing to conventional trojan attack methods. The experimental results show that TrojanNet can inject the trojan into all labels simultaneously (all-label trojan attack) and achieves 100% attack success rate without affecting model accuracy on original tasks. Experimental analysis further demonstrates that state-of-the-art trojan detection algorithms fail to detect TrojanNet attack. The code is available at https://github.com/trx14/TrojanNet.\n\n", "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Ruixiang Tang', 'interest': 'Chest Ct'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_abstract = target_publication_info['abstract']\nfinal_result = target_abstract\n", "result": "With the widespread use of deep neural networks (DNNs) in high-stake applications, the security problem of the DNN models has received extensive attention. In this paper, we investigate a specific security problem called trojan attack, which aims to attack deployed DNN systems relying on the hidden trigger patterns inserted by malicious hackers. We propose a training-free attack approach which is different from previous work, in which trojaned behaviors are injected by retraining model on a poisoned dataset. Specifically, we do not change parameters in the original model but insert a tiny trojan module (TrojanNet) into the target model. The infected model with a malicious trojan can misclassify inputs into a target label when the inputs are stamped with the special trigger. The proposed TrojanNet has several nice properties including (1) it activates by tiny trigger patterns and keeps silent for other signals, (2) it is model-agnostic and could be injected into most DNNs, dramatically expanding its attack scenarios, and (3) the training-free mechanism saves massive training efforts comparing to conventional trojan attack methods. The experimental results show that TrojanNet can inject the trojan into all labels simultaneously (all-label trojan attack) and achieves 100% attack success rate without affecting model accuracy on original tasks. Experimental analysis further demonstrates that state-of-the-art trojan detection algorithms fail to detect TrojanNet attack. The code is available at https://github.com/trx14/TrojanNet.\n\n", "exe_time": 4.280496597290039}
{"Query_en": "What is the PDF link of the representative work of Dennis Fedorishin in Representation Learning field?", "Answer": "https://static.aminer.cn/upload/pdf/1651/841/101/5eccb534e06a4c1b26a83a4d_0.pdf", "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Dennis Fedorishin', 'interest': 'Representation Learning'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_pdf = target_publication_info['pdf_link']\nfinal_result = target_pdf\n", "result": "https://static.aminer.cn/upload/pdf/1651/841/101/5eccb534e06a4c1b26a83a4d_0.pdf", "exe_time": 4.299836874008179}
{"Query_en": "Which journal or conference included the representative work of Eric Tzeng in Learning By Example field?", "Answer": {"id": "53a72e9120f7420be8c9281e", "info": {"name": "ICML"}, "issue": "", "type": 0, "volume": "abs/1310.1531"}, "route": "searchPerson -> getPersonPubs -> getPublication", "code": "info = {'name': 'Eric Tzeng', 'interest': 'Learning By Example'}\nname = info['name']\ninterest = info['interest']\n\nperson_list = searchPerson(name = name, interest = interest)\ntarget_person_info = person_list[0]\ntarget_person_id = target_person_info['person_id']\ntarget_person_pubs = getPersonPubs(person_id = target_person_id)\ntarget_publication_dict = target_person_pubs[0]\ntarget_publication_id = target_publication_dict['pub_id']\ntarget_publication_info = getPublication(pub_id = target_publication_id)\ntarget_venue = target_publication_info['venue']\nfinal_result = target_venue\n", "result": {"id": "53a72e9120f7420be8c9281e", "info": {"name": "ICML"}, "issue": "", "type": 0, "volume": "abs/1310.1531"}, "exe_time": 4.284686326980591}
